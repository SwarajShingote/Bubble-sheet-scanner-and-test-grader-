{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Name : Bubble sheet scanner and test grader using OMR, Python, and OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optical Mark Recognition (OMR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optical Mark Recognition, or OMR for short, is the process of automatically analyzing human-marked documents and interpreting their results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implemention Algortithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1: Detecting the exam in an image.\n",
    "\n",
    "2: Applying a perspective transform to extract the top-down, birds-eye-view of the exam.\n",
    "\n",
    "3: Extracting the set of bubbles (i.e., the possible answer choices) from the perspective transformed exam.\n",
    "\n",
    "4: Sorting the questions/bubbles into rows.\n",
    "\n",
    "5: Determining the marked (i.e., “bubbled in”) answer for each row.\n",
    "\n",
    "6: Looking up the correct answer in our answer key to determine if the user was correct in their choice.\n",
    "\n",
    "7: Repeating for all questions in the exam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perspective Transformation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Perspective Transformation, , we can change the perspective of a given image or video for getting better insights about the required information. In Perspective Transformation, we need provide the points on the image from which want to gather information by changing the perspective. We also need to provide the points inside which we want to display our image. Then, we get the perspective transform from the two given set of points and wrap it with the original image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the necessary packages\n",
    "\n",
    "from imutils.perspective import four_point_transform\n",
    "from imutils import contours\n",
    "import numpy as np\n",
    "import imutils\n",
    "import cv2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the answer key which maps the question number\n",
    "# to the correct answer\n",
    "\n",
    "# (Q.1 - B ,Q.2 - E, Q.3 - A, Q.4 - D, Q.5 - B)\n",
    "\n",
    "ANSWER_KEY = {0: 1, 1: 4, 2: 0, 3: 3, 4: 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the image, converting it to grayscale, blurring it\n",
    "# slightly, then finding edges\n",
    "\n",
    "image = cv2.imread(\"test_01.png\")\n",
    "gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "blurred = cv2.GaussianBlur(gray,(5,5),0)\n",
    "edged = cv2.Canny(blurred,75,200)\n",
    "# cv2.imshow(\"Output\",image)\n",
    "# cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding contours in the edge map, then initializing\n",
    "# the contour that corresponds to the document\n",
    "\n",
    "cnts = cv2.findContours(edged.copy(),cv2.RETR_EXTERNAL,\n",
    "                       cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "cnts = imutils.grab_contours(cnts)\n",
    "\n",
    "docCnt = None\n",
    "\n",
    "# at least one contour was found\n",
    "# sorting the contours according to their size in\n",
    "# descending order\n",
    "\n",
    "if len(cnts)>0:\n",
    "    cnts = sorted(cnts , key = cv2.contourArea , reverse = True)\n",
    "\n",
    "#looping over the contours\n",
    "# then approximate the contour\n",
    "\n",
    "    for c in cnts :\n",
    "        peri = cv2.arcLength(c,True)\n",
    "        approx = cv2.approxPolyDP(c, 0.02*peri, True)\n",
    "        \n",
    "        if len(approx) == 4 :\n",
    "            docCnt = approx\n",
    "            break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying a four point perspective transform to both the\n",
    "# original image and grayscale image to obtain a top-down\n",
    "# birds eye view of the paper\n",
    "\n",
    "\n",
    "paper = four_point_transform(image,docCnt.reshape(4,2))\n",
    "warped = four_point_transform(gray,docCnt.reshape(4,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.imshow(\"Output\",warped)\n",
    "# cv2.waitKey(0)\n",
    "\n",
    "# cv2.imshow(\"Output\",warped)\n",
    "# cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying Otsu's thresholding method to binarize the warped\n",
    "# piece of paper\n",
    "\n",
    "thresh = cv2.threshold(warped,0,255,cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "\n",
    "# cv2.imshow(\"Output\",thresh)\n",
    "# cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_grader(image):\n",
    "    \n",
    "    # finding contours in the thresholded image, then initializing\n",
    "    # the list of contours that correspond to questions\n",
    "    \n",
    "    image = cv2.imread(image)\n",
    "    cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "    questionCnts = []\n",
    "\n",
    "    # looping over the contours\n",
    "\n",
    "    for c in cnts:\n",
    "        # computing the bounding box of the contour, then using the\n",
    "        # bounding box to derive the aspect ratio\n",
    "\n",
    "        (x, y, w, h) = cv2.boundingRect(c)\n",
    "        ar = w / float(h)\n",
    "\n",
    "        # in order to label the contour as a question, region\n",
    "        # should be sufficiently wide, sufficiently tall, and\n",
    "        # have an aspect ratio approximately equal to 1\n",
    "\n",
    "        if w >= 20 and h >= 20 and ar >= 0.9 and ar <= 1.1:\n",
    "            questionCnts.append(c)\n",
    "\n",
    "    # sorting the question contours top-to-bottom, then initialize\n",
    "    # the total number of correct answers\n",
    "\n",
    "    questionCnts = contours.sort_contours(questionCnts,\n",
    "    method=\"top-to-bottom\")[0]\n",
    "    correct = 0\n",
    "\n",
    "    # each question has 5 possible answers, to loop over the\n",
    "    # question in batches of 5\n",
    "\n",
    "    for (q, i) in enumerate(np.arange(0, len(questionCnts), 5)):\n",
    "\n",
    "        # sorting the contours for the current question from\n",
    "        # left to right, then initialize the index of the\n",
    "        # bubbled answer\n",
    "\n",
    "        cnts = contours.sort_contours(questionCnts[i:i + 5])[0]\n",
    "        bubbled = None\n",
    "\n",
    "        # loop over the sorted contours\n",
    "        for (j, c) in enumerate(cnts):\n",
    "            # constructing a mask that reveals only the current\n",
    "            # \"bubble\" for the question\n",
    "\n",
    "            mask = np.zeros(thresh.shape, dtype=\"uint8\")\n",
    "            cv2.drawContours(mask, [c], -1, 255, -1)\n",
    "\n",
    "            # applying the mask to the thresholded image, then\n",
    "            # count the number of non-zero pixels in the\n",
    "            # bubble area\n",
    "\n",
    "            mask = cv2.bitwise_and(thresh, thresh, mask=mask)\n",
    "            total = cv2.countNonZero(mask)\n",
    "\n",
    "            # if the current total has a larger number of total\n",
    "            # non-zero pixels, then we are examining the currently\n",
    "            # bubbled-in answer\n",
    "\n",
    "            if bubbled is None or total > bubbled[0]:\n",
    "                bubbled = (total, j)\n",
    "\n",
    "        # initializing the contour color and the index of the\n",
    "        # *correct* answer\n",
    "\n",
    "        color = (0, 0, 255)\n",
    "        k = ANSWER_KEY[q]\n",
    "\n",
    "        # check to see if the bubbled answer is correct\n",
    "        if k == bubbled[1]:\n",
    "            color = (0, 255, 0)\n",
    "            correct += 1\n",
    "\n",
    "        # draw the outline of the correct answer on the test\n",
    "        cv2.drawContours(paper, [cnts[k]], -1, color, 3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the function\n",
    "\n",
    "test_grader(\"test_01.png\")\n",
    "\n",
    "score = (correct / 5.0) * 100\n",
    "print(\"[INFO] Obtained score: {:.2f}%\".format(score))\n",
    "\n",
    "cv2.putText(paper, \"Score:{:.2f}%\".format(score), (10, 30),\n",
    "cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
    "cv2.imshow(\"Original\", image)\n",
    "cv2.imshow(\"Exam\", paper)\n",
    "cv2.waitKey(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
